<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Jungho Lee</title>
  
  <meta name="author" content="Jungho Lee">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" href="images/logo/yonsei_logo.png">
	<!-- <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>"> -->
</head>

<body>
  <table style="width:100%;max-width:1000px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Jungho Lee</name>
              </p>
              <p>
                I am a Ph.D candidate at <a href="https://www.yonsei.ac.kr">Yonsei University</a> in <a href="https://en.wikipedia.org/wiki/Seoul">Seoul</a>, where I work on computer vision and machine learning.
              </p>
              <p>
                My primary areas of research are 3D computer vision techniques including Neural Radiance Fields (NeRF), and video understanding, specifically focusing on action recognition.
              </p>
              <p>
                I'm always open to collaborations or suggestions. Please feel free to contact me if you have any questions or suggestions. :)
              </p>
              <p style="text-align:center">
                <a href="mailto:2015142131@yonsei.ac.kr">Email</a> &nbsp/&nbsp
                <a href="data/resume/CV.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.co.kr/citations?user=NAj3cTcAAAAJ&hl=ko">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/Jho-Yonsei/">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <img style="width:100%;max-width:100%" alt="profile photo" src="images/profile/JunghoLee.png">
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Publication</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
				
          
<tr onmouseout="hdgcn_stop()" onmouseover="hdgcn_start()" bgcolor="#ffffd0">
  <td style="padding:20px;width:30%;height:240px;vertical-align:top">
    <div class="one">
      <div class="two" id='hdgcn_image'>
        <img src='images/hdgcn/hdgcn_after.png' width="240"></div>
      <img src='images/hdgcn/hdgcn_before.png' width="240">
    </div>
    <script type="text/javascript">
      function hdgcn_start() {
        document.getElementById('hdgcn_image').style.opacity = "1";
      }

      function hdgcn_stop() {
        document.getElementById('hdgcn_image').style.opacity = "0";
      }
      hdgcn_stop()
    </script>
  </td>
  <td style="padding:20px;width:70%;height:240px;vertical-align:middle">
    <a href="https://arxiv.org/pdf/2208.10741.pdf">
      <papertitle>Hierarchically Decomposed Graph Convolutional Networks for Skeleton-Based Action Recognition</papertitle>
    </a>
    <br>
    <strong>Jungho Lee</strong>,
    <a href="https://hydragon.co.kr">Minhyeok Lee</a>,
    <a href="https://dogyoonlee.github.io/">Dogyoon Lee</a>,
    <a href="https://scholar.google.com/citations?user=b7A10VYAAAAJ&hl=ko&oi=ao">Sangyoun Lee</a>
    <br>
    <em>IEEE/CVF International Conference on Computer Vision (<strong>ICCV</strong>)</em>, 2023 
    <br>
    [
    <a href="https://arxiv.org/pdf/2208.10741.pdf">Paper</a>
    /
    <a href="https://github.com/Jho-Yonsei/HD-GCN">Code</a>
    /
    <a href="data/bib/hdgcn2023.txt">bib</a>
    ]
    <p></p>
    <p>
    We propose a hierarchically decomposed graph convolution with a novel hierarchically decomposed graph, which consider the sematic correlation between the joints and the edges of the human skeleton.
    </p>
  </td>
</tr>

<tr onmouseout="stcnet_stop()" onmouseover="stcnet_start()" bgcolor="#ffffd0">
  <td style="padding:20px;width:30%;height:240px;vertical-align:top">
    <div class="one">
      <div class="two" id='stcnet_image'>
        <img src='images/stcnet/stcnet_after.png' width="240"></div>
      <img src='images/stcnet/stcnet_before.png' width="240">
    </div>
    <script type="text/javascript">
      function stcnet_start() {
        document.getElementById('stcnet_image').style.opacity = "1";
      }

      function stcnet_stop() {
        document.getElementById('stcnet_image').style.opacity = "0";
      }
      stcnet_stop()
    </script>
  </td>
  <td style="padding:20px;width:70%;height:240px;vertical-align:middle">
    <a href="https://arxiv.org/pdf/2212.04761.pdf">
      <papertitle>Leveraging Spatio-Temporal Dependency for Skeleton-Based Action Recognition</papertitle>
    </a>
    <br>
    <strong>Jungho Lee</strong>,
    <a href="https://hydragon.co.kr">Minhyeok Lee</a>,
    <a href="https://suhwan-cho.github.io/">Suhwan Cho</a>,
    <a href="https://scholar.google.com/citations?user=q1BRGh0AAAAJ&hl=ko">Sungmin Woo</a>,
    <a href="https://scholar.google.com/citations?user=93X9IUsAAAAJ&hl=ko">Sungjun Jang</a>,
    <a href="https://scholar.google.com/citations?user=b7A10VYAAAAJ&hl=ko&oi=ao">Sangyoun Lee</a>
    <br>
    <em>IEEE/CVF International Conference on Computer Vision (<strong>ICCV</strong>)</em>, 2023 
    <br>
    [
    <a href="https://arxiv.org/pdf/2212.04761.pdf">Paper</a>
    /
    <a href="https://github.com/Jho-Yonsei/STC-Net">Code</a>
    /
    <a href="data/bib/stcnet2023.txt">bib</a>
    ]
    <p></p>
    <p>
      We propose a novel Spatio-Temporal Curve Network (STC-Net) for skeleton-based action recognition, which consists of spatial modules with an spatio-temporal curve (STC) module and graph convolution with dilated kernels (DK-GC)
    </p>
  </td>
</tr>

</tbody></table>

<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
  <tr>
  <td style="padding:20px;width:100%;vertical-align:middle">
    <heading></heading>
  </td>
</tr>
</tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Pending</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
					
          <tr onmouseout="glcod_stop()" onmouseover="glcod_start()">
            <td style="padding:20px;width:30%;height:220px;vertical-align:top">
              <div class="one">
                <div class="two" id='gl_cod_image'>
                  <img src='images/gl_cod/gl_cod_after.png' width="240"></div>
                <img src='images/gl_cod/gl_cod_before.png' width="240">
              </div>
              <script type="text/javascript">
                function glcod_start() {
                  document.getElementById('gl_cod_image').style.opacity = "1";
                }
          
                function glcod_stop() {
                  document.getElementById('gl_cod_image').style.opacity = "0";
                }
                glcod_stop()
              </script>
            </td>
            <td style="padding:20px;width:70%;height:220px;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2211.12048.pdf">
                <papertitle>Global-Local Aggregation with Deformable Point Sampling for Camouflaged Object Detection</papertitle>
              </a>
              <br>
              <a href="https://hydragon.co.kr">Minhyeok Lee</a>,
              <a href="https://suhwan-cho.github.io">Suhwan Cho</a>,
              <a href="https://scholar.google.com/citations?user=OskGL0sAAAAJ&hl=ko&oi=ao">Chaewon Park</a>,
              <a href="https://dogyoonlee.github.io">Dogyoon Lee</a>,
              <strong>Jungho Lee</strong>,
              <a href="https://scholar.google.com/citations?user=b7A10VYAAAAJ&hl=ko&oi=ao">Sangyoun Lee</a>
              <br>
              <em>Pending</em>, 2023 
              <br>
              [
              <a href="https://arxiv.org/pdf/2211.12048.pdf">Paper</a>
              /
              <a href="https://hydragon.co.kr/">Code</a>
              /
              <a href="data/bib/gl_cod2023.txt">bib</a>
              ]
              <p></p>
              <p>
              We propose novel deformable point sampling method and global-local aggregation architecture to integrate object's global information, background, and boundary local information to improve the camouflaged object detection.
              </p>
            </td>
          </tr>
          

          <tr onmouseout="gsa_stop()" onmouseover="gsa_start()">
            <td style="padding:20px;width:30%;height:220px;vertical-align:top">
              <div class="one">
                <div class="two" id='gsa_image'>
                  <img src='images/gsa/slot_attention_after.png' width="240"></div>
                <img src='images/gsa/slot_attention_before.png' width="240">
              </div>
              <script type="text/javascript">
                function gsa_start() {
                  document.getElementById('gsa_image').style.opacity = "1";
                }
          
                function gsa_stop() {
                  document.getElementById('gsa_image').style.opacity = "0";
                }
                gsa_stop()
              </script>
            </td>
            <td style="padding:20px;width:70%;height:220px;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2303.08314.pdf">
                <papertitle>Guided Slot Attention for Unsupervised Video Object Segmentation</papertitle>
              </a>
              <br>
              <a href="https://hydragon.co.kr">Minhyeok Lee</a>,
              <a href="https://suhwan-cho.github.io">Suhwan Cho</a>,
              <a href="https://dogyoonlee.github.io/">Dogyoon Lee</a>,
              <a href="https://scholar.google.com/citations?user=OskGL0sAAAAJ&hl=ko&oi=ao">Chaewon Park</a>,
              <strong>Jungho Lee</strong>,
              <a href="https://scholar.google.com/citations?user=b7A10VYAAAAJ&hl=ko&oi=ao">Sangyoun Lee</a>
              <br>
              <em>Pending</em>, 2023 
              <br>
              [
              <a href="https://arxiv.org/pdf/2303.08314.pdf">Paper</a>
              /
              <a href="https://">Code</a>
              /
              <a href="https://">bib</a>
              ]
              <p></p>
              <p>
              We propose a guided slot attention network to reinforce spatial structural information and obtain better foreground‚Äìbackground separation.
              </p>
            </td>
          </tr>
        

					
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                This website's source code is borrowed from <a href="https://github.com/jonbarron/jonbarron_website">jonbarron's website</a>.
              </p>
              <p style="text-align:right;font-size:small;">
                Last updated July 2023.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
